## 论文
### 基础方法类
#### [《The Power of Scale for Parameter - Efficient Prompt Tuning》2021谷歌提出Prompt Tunning](https://arxiv.org/abs/2104.08691)
#### [《Prefix - Tuning: Optimizing Continuous Prompts for Generation》2021OpenAI提出 Prefix Tuning](https://arxiv.org/abs/2101.00190)
#### [《LoRA: Low-Rank Adaptation of Large Language Models》2021微软团队提出LoRA](https://arxiv.org/abs/2106.09685)

## 视频
### 科普视频
#### [想微调特定领域的 DeepSeek，数据集究竟要怎么搞（理论篇）？](https://www.bilibili.com/video/BV1z9RLYWEjq/)